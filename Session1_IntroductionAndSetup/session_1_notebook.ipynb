{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b842e33-3c4f-45b4-aea8-de94afad4b2e",
   "metadata": {},
   "source": [
    "# Introduction and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253517f7-860b-422b-bd04-c747e79061a7",
   "metadata": {},
   "source": [
    "Initially, we require several libraries and scientific modules for our tasks. Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee2a05b-92e3-48e2-8525-f215d63de599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "\n",
    "# Scientific libraries\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "#Visualization libraries\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import emoji\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5de5f9a-c538-4f38-a7f6-7d481c6c354f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is a command specific to Jupyter Notebooks that ensures Matplotlib plots are embedded\n",
    "# and displayed directly within the notebook interface, independent of the Jupyter version.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660a6204-9444-4d6a-82e1-5fd58d84733c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is ðŸ‘\n"
     ]
    }
   ],
   "source": [
    "print(emoji.emojize('Python is :thumbs_up:'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51734b",
   "metadata": {},
   "source": [
    "### Working with netCDF data \n",
    "\n",
    "**Downloading the 2023 Monthly Wind Data**\n",
    "\n",
    "Navigate to the Copernicus Marine Service website to access the 2023 monthly wind data. Specifically, download the 12 NetCDF files for 2023 from the following link:\n",
    "https://data.marine.copernicus.eu/product/WIND_GLO_PHY_CLIMATE_L4_MY_012_003/files?path=WIND_GLO_PHY_CLIMATE_L4_MY_012_003%2Fcmems_obs-wind_glo_phy_my_l4_P1M_202211%2F2023%2F&subdataset=cmems_obs-wind_glo_phy_my_l4_P1M_202211\n",
    "\n",
    "Once downloaded, store the data in `OceanographicDataProcessingCourse/Data/Wind`\n",
    "\n",
    "In the cell below, please provide the file path to where you've stored the downloaded data. This will allow for the data to be accessed and processed in the subsequent steps. You can use a relative or absolute path. For example: `C:/PATH/TO/FILE` on any operating system. Today, we start with the data of January 2023.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbae142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## datapath and filename\n",
    "datapath = '../Data/Wind'\n",
    "filename = \"cmems_obs-wind_glo_phy_my_l4_P1M_202301.nc\"\n",
    "\n",
    "shapefile = '../Data/110m_cultural/ne_110m_admin_0_countries.shp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41fca7b",
   "metadata": {},
   "source": [
    "Since geographic data files can often be very large, when we first open our data file in xarray it simply loads the metadata associated with the file. We can then view summary information about the contents of the file before deciding whether weâ€™d like to load some or all of the data into memory ( xarray allows for a quick view of the dataset's metadata without loading the full data, but once the data is accessed, it will be loaded.). Run the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cf27239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the cell\n",
    "full_path = os.path.join(datapath, filename)\n",
    "ds = xr.open_dataset(full_path, decode_times=True, use_cftime=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d218eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Conventions',\n",
       " '_HANDLED_TYPES',\n",
       " '__abs__',\n",
       " '__abstractmethods__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_ufunc__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__dask_graph__',\n",
       " '__dask_keys__',\n",
       " '__dask_layers__',\n",
       " '__dask_optimize__',\n",
       " '__dask_postcompute__',\n",
       " '__dask_postpersist__',\n",
       " '__dask_scheduler__',\n",
       " '__dask_tokenize__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__ilshift__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__orig_bases__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rfloordiv__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_abc_impl',\n",
       " '_all_compat',\n",
       " '_assert_all_in_dataset',\n",
       " '_attr_sources',\n",
       " '_attrs',\n",
       " '_binary_op',\n",
       " '_cache',\n",
       " '_calc_assign_results',\n",
       " '_calculate_binary_op',\n",
       " '_close',\n",
       " '_construct_dataarray',\n",
       " '_construct_direct',\n",
       " '_coord_names',\n",
       " '_copy',\n",
       " '_copy_attrs_from',\n",
       " '_copy_listed',\n",
       " '_cum_extra_args_docstring',\n",
       " '_dask_postcompute',\n",
       " '_dask_postpersist',\n",
       " '_dims',\n",
       " '_encoding',\n",
       " '_get_indexers_coords_and_indexes',\n",
       " '_get_stack_index',\n",
       " '_indexes',\n",
       " '_inplace_binary_op',\n",
       " '_integrate_one',\n",
       " '_ipython_key_completions_',\n",
       " '_isel_fancy',\n",
       " '_item_sources',\n",
       " '_normalize_dim_order',\n",
       " '_overwrite_indexes',\n",
       " '_persist_inplace',\n",
       " '_reduce_extra_args_docstring',\n",
       " '_reduce_method',\n",
       " '_reindex',\n",
       " '_reindex_callback',\n",
       " '_rename',\n",
       " '_rename_all',\n",
       " '_rename_dims',\n",
       " '_rename_indexes',\n",
       " '_rename_vars',\n",
       " '_replace',\n",
       " '_replace_vars_and_dims',\n",
       " '_replace_with_new_dims',\n",
       " '_repr_html_',\n",
       " '_resample',\n",
       " '_set_numpy_data_from_dataframe',\n",
       " '_set_sparse_data_from_dataframe',\n",
       " '_setattr_dict',\n",
       " '_setitem_check',\n",
       " '_stack_once',\n",
       " '_to_dataframe',\n",
       " '_unary_op',\n",
       " '_unstack_full_reindex',\n",
       " '_unstack_once',\n",
       " '_validate_indexers',\n",
       " '_validate_interp_indexers',\n",
       " '_variables',\n",
       " 'all',\n",
       " 'any',\n",
       " 'apply',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'as_numpy',\n",
       " 'assign',\n",
       " 'assign_attrs',\n",
       " 'assign_coords',\n",
       " 'astype',\n",
       " 'attrs',\n",
       " 'bfill',\n",
       " 'broadcast_equals',\n",
       " 'broadcast_like',\n",
       " 'chunk',\n",
       " 'chunks',\n",
       " 'chunksizes',\n",
       " 'clip',\n",
       " 'close',\n",
       " 'coarsen',\n",
       " 'combine_first',\n",
       " 'compute',\n",
       " 'conj',\n",
       " 'conjugate',\n",
       " 'convert_calendar',\n",
       " 'coords',\n",
       " 'copy',\n",
       " 'count',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'cumulative',\n",
       " 'cumulative_integrate',\n",
       " 'curvefit',\n",
       " 'data_vars',\n",
       " 'date_created',\n",
       " 'date_modified',\n",
       " 'diff',\n",
       " 'differentiate',\n",
       " 'dims',\n",
       " 'drop',\n",
       " 'drop_attrs',\n",
       " 'drop_dims',\n",
       " 'drop_duplicates',\n",
       " 'drop_encoding',\n",
       " 'drop_indexes',\n",
       " 'drop_isel',\n",
       " 'drop_sel',\n",
       " 'drop_vars',\n",
       " 'dropna',\n",
       " 'dtypes',\n",
       " 'dump_to_store',\n",
       " 'eastward_stress',\n",
       " 'eastward_stress_bias',\n",
       " 'eastward_stress_sdd',\n",
       " 'eastward_wind',\n",
       " 'eastward_wind_bias',\n",
       " 'eastward_wind_sdd',\n",
       " 'encoding',\n",
       " 'equals',\n",
       " 'eval',\n",
       " 'expand_dims',\n",
       " 'ffill',\n",
       " 'fillna',\n",
       " 'filter_by_attrs',\n",
       " 'from_dataframe',\n",
       " 'from_dict',\n",
       " 'geospatial_lat_max',\n",
       " 'geospatial_lat_min',\n",
       " 'geospatial_lat_resolution',\n",
       " 'geospatial_lat_units',\n",
       " 'geospatial_lon_max',\n",
       " 'geospatial_lon_min',\n",
       " 'geospatial_lon_resolution',\n",
       " 'geospatial_lon_units',\n",
       " 'get',\n",
       " 'get_index',\n",
       " 'groupby',\n",
       " 'groupby_bins',\n",
       " 'head',\n",
       " 'history',\n",
       " 'identical',\n",
       " 'idxmax',\n",
       " 'idxmin',\n",
       " 'imag',\n",
       " 'indexes',\n",
       " 'info',\n",
       " 'institution',\n",
       " 'instrument',\n",
       " 'instrument_vocabulary',\n",
       " 'integrate',\n",
       " 'interp',\n",
       " 'interp_calendar',\n",
       " 'interp_like',\n",
       " 'interpolate_na',\n",
       " 'isel',\n",
       " 'isin',\n",
       " 'isnull',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'keywords',\n",
       " 'lat',\n",
       " 'load',\n",
       " 'load_store',\n",
       " 'loc',\n",
       " 'lon',\n",
       " 'map',\n",
       " 'map_blocks',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'merge',\n",
       " 'min',\n",
       " 'nbytes',\n",
       " 'northward_stress',\n",
       " 'northward_stress_bias',\n",
       " 'northward_stress_sdd',\n",
       " 'northward_wind',\n",
       " 'northward_wind_bias',\n",
       " 'northward_wind_sdd',\n",
       " 'notnull',\n",
       " 'number_of_observations',\n",
       " 'pad',\n",
       " 'persist',\n",
       " 'pipe',\n",
       " 'platform',\n",
       " 'platform_vocabulary',\n",
       " 'plot',\n",
       " 'polyfit',\n",
       " 'processing_level',\n",
       " 'prod',\n",
       " 'project',\n",
       " 'quantile',\n",
       " 'query',\n",
       " 'rank',\n",
       " 'real',\n",
       " 'reduce',\n",
       " 'references',\n",
       " 'reindex',\n",
       " 'reindex_like',\n",
       " 'rename',\n",
       " 'rename_dims',\n",
       " 'rename_vars',\n",
       " 'reorder_levels',\n",
       " 'resample',\n",
       " 'reset_coords',\n",
       " 'reset_encoding',\n",
       " 'reset_index',\n",
       " 'roll',\n",
       " 'rolling',\n",
       " 'rolling_exp',\n",
       " 'round',\n",
       " 'sel',\n",
       " 'set_close',\n",
       " 'set_coords',\n",
       " 'set_index',\n",
       " 'set_xindex',\n",
       " 'shift',\n",
       " 'sizes',\n",
       " 'sortby',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'std',\n",
       " 'sum',\n",
       " 'summary',\n",
       " 'swap_dims',\n",
       " 'tail',\n",
       " 'thin',\n",
       " 'time',\n",
       " 'time_coverage_end',\n",
       " 'time_coverage_start',\n",
       " 'title',\n",
       " 'to_array',\n",
       " 'to_dask_dataframe',\n",
       " 'to_dataarray',\n",
       " 'to_dataframe',\n",
       " 'to_dict',\n",
       " 'to_netcdf',\n",
       " 'to_pandas',\n",
       " 'to_stacked_array',\n",
       " 'to_zarr',\n",
       " 'transpose',\n",
       " 'unify_chunks',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'values',\n",
       " 'var',\n",
       " 'variables',\n",
       " 'weighted',\n",
       " 'where',\n",
       " 'xindexes']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1669d5d6",
   "metadata": {},
   "source": [
    "An xarray has typically the following components:  \n",
    "data : data array ( values)  \n",
    "dims : list of dimensions  \n",
    "coords : dictonary which shows dimensions with corresponding coordinates and data types\n",
    "attrs : dictionary with metadata and attributes  \n",
    "Have a look into the xarray ds (e.g. ds.attrs ... ) by running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cell\n",
    "print('Attributes: ', ds.attrs)\n",
    "print('Coordinates: ', ds.coords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d39cce",
   "metadata": {},
   "source": [
    "When you simply input `ds` in a cell of a Jupyter Notebook, little arrows may appear for some objects, allowing you to interactively expand and view the entire content. It's an interactive feature provided by Jupyter to help manage and navigate long outputs more efficiently. You can click on these arrows to expand or collapse the full content of an object. When you only want to have a list of your variables you can simply use list(ds.data_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553637c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run the cell \n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40856d13",
   "metadata": {},
   "source": [
    "Alternatively you can use the `print()`-Statement, which is also helpful when you work with excecutable Python Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce36340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the cell\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ef190",
   "metadata": {},
   "source": [
    "\n",
    "You've already observed the variables within the dataset. Another method to display the variables included in the dataset is to simply use `list()` on `data_vars`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a67f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the cell\n",
    "list(ds.data_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbab0aad",
   "metadata": {},
   "source": [
    "From this point, you'll have a clear overview of what's contained in the data. You'll also be able to see how the data is distributed both temporally and spatially. If you can't immediately discern the resolution of the data, the following code snippet will assist you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5474c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cell\n",
    "if 'lon' in ds.dims and len(ds.lon) > 1:\n",
    "    print(\"Longitude resolution:\", ds.lon.values[1] - ds.lon.values[0])\n",
    "if 'lat' in ds.dims and len(ds.lat) > 1:\n",
    "    print(\"Latitude resolution:\", ds.lat.values[1] - ds.lat.values[0])\n",
    "if 'time' in ds.dims and len(ds.time) > 1:\n",
    "    print(\"Temporal resolution:\", ds.time.values[1] - ds.time.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40943d6",
   "metadata": {},
   "source": [
    "You might have noticed the absence of an output for temporal resolution. Why might that be? Although the dataset has a `'time'` dimension, it doesn't truly have a temporal resolution since there's only one time value. This indicates that the data is monthly.  \n",
    "\n",
    "You can see, which variables the data set includes and which dimension they have. We are interested in the u and v variable contained within that xarray dataset and named here `eastward_wind` and `northward_wind`:\n",
    "\n",
    "In the xarray library, a dataset (often denoted as ds) represents an in-memory on-disk database of arrays. These arrays can be thought of as variables in the dataset. There are two primary ways to access these variables:\n",
    "\n",
    "1. Attribute-style access: `ds.variable_name`\n",
    "2. Dictionary-style access: `ds['variable_name']`\n",
    "\n",
    "Attribute access is shorter but might not always work, especially with invalid Python names (e.g. '123' or 'print'). Dictionary access is more universal and works with any variable name.\n",
    "\n",
    "Testing both access' by running the next two cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b484c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cell\n",
    "ds.eastward_wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4ffa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the cell\n",
    "ds['eastward_wind']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f7368d",
   "metadata": {},
   "source": [
    "Both lines should produce the same output, assuming that `eastward_wind` is a valid variable in your dataset. If not, you'd get an error.\n",
    "\n",
    "In summary, both methods are valid ways to access xarray Dataset variables, and which one to use often comes down to personal preference, the specific situation, and the variable names you're working with.\n",
    "\n",
    "### Handling Nan Values in Data\n",
    "\n",
    "In the following, we check if the eastward wind has missing values (NaN - not a number):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196bb2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cell\n",
    "\n",
    "# Count the number of NaNs per grid point across the time dimension\n",
    "nan_mask = ds.eastward_wind.isnull().sum(dim='time')\n",
    "\n",
    "# Plot the NaN mask to visualize where NaN values are present\n",
    "plt.figure(figsize=(10, 6))\n",
    "nan_mask.plot()\n",
    "plt.title('Number of NaN Values per Grid Cell')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214d33e4",
   "metadata": {},
   "source": [
    "No missing values were found within the eastward wind component. Itâ€™s a good practice to check for missing values (NaNs) in your dataset because they can cause issues during calculations, such as in averaging, interpolation, or contouring operations. Identifying and handling NaNs early helps avoid potential errors or inaccurate results. In this case, no missing values are present, but itâ€™s still important to perform this check for other variables within the dataset (e.g., the northward wind component) to ensure the integrity of your data processing. \n",
    "\n",
    "\n",
    "## Visualization\n",
    "\n",
    "With `xarray`'s built-in plotting functionality, we can easily visualize DataArrays. Here, we are plotting `ds.eastward_wind` at the time index `time = 0` for all values of latitude and longitude using `ds.eastward_wind[0,:,:]`. If this dataset contained data for multiple months, we would specify the desired time index accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7736dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot eastward wind using xarray's built-in plotting functionality\n",
    "ds.eastward_wind[0,:,:].plot(cmap='coolwarm', figsize=(12, 5))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b23677b",
   "metadata": {},
   "source": [
    "This plot already looks quite impressive! We can observe the zonal wind velocity, with positive amplitudes in the mid-latitudes and negative amplitudes in the higher latitudes, as well as between -20Â° and 20Â°. However, now we also want to visualize the continents and add the spatial grid to the plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b15fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shapefile of the world map\n",
    "world = gpd.read_file(shapefile)\n",
    "\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# Plot eastward wind using xarray's built-in plotting functionality\n",
    "# This uses the existing data from an xarray Dataset (e.g., ds)\n",
    "ds.eastward_wind[0,:,:].plot(ax=ax, cmap='coolwarm')\n",
    "\n",
    "# Plot the world map (continents)\n",
    "world.plot(ax=ax, color='none', edgecolor='black', linewidth=1)\n",
    "\n",
    "# Add gridlines\n",
    "ax.set_xticks(range(-180, 181, 30))  # Longitude gridlines every 30Â°\n",
    "ax.set_yticks(range(-90, 91, 30))    # Latitude gridlines every 30Â°\n",
    "ax.grid(True, linestyle='--', color='gray')  # Dashed gridlines\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c974e05",
   "metadata": {},
   "source": [
    "First, we load the shapefile containing the country borders as `world`. We create the figure and axis, and plot the eastward wind using xarray's built-in plotting functionality as before. After that, we plot the landmasses and ensure both plots are drawn on the same axis. Finally, we add gridlines and apply a specific style to them.\n",
    "\n",
    "\n",
    "When you take a closer look at the code snippet above, where do you think you could change the color of the landmasses and the borders, for example?\n",
    "\n",
    "**Exercise 1: Copy the code from above and modify it to change the color of the landmasses and borders. Experiment and see how different color schemes affect the visualization.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c448fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the code from above change the relevant paramters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043dff45",
   "metadata": {},
   "source": [
    "The xarray.plot() function expects regularly gridded data on a flat, linear axis, which could result in distorted representations of the Earth. In flat projections, the sizes and shapes of geographical features are not accurate â€” for example, landmasses near the poles appear much larger than they actually are. To create more realistic representations of the Earth, we could use map projections, such as the Robinson projection.\n",
    "\n",
    "For this, we use `Basemap`, which comes with built-in coastlines, so thereâ€™s no need to load a separate shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85933373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the cell\n",
    "\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Define the map projection using Robinson (Basemap for Robinson projection)\n",
    "m = Basemap(projection='robin', lon_0=0, ax=ax)\n",
    "\n",
    "# Get longitude and latitude data from the dataset\n",
    "lon = ds.coords['lon'].values\n",
    "lat = ds.coords['lat'].values\n",
    "\n",
    "# Create a meshgrid for plotting\n",
    "lon2d, lat2d = np.meshgrid(lon, lat)\n",
    "\n",
    "# Transform the coordinates into the Robinson projection\n",
    "x, y = m(lon2d, lat2d)\n",
    "\n",
    "# Define levels for contouring (for eastward wind)\n",
    "levels = np.linspace(-12, 12, 30)\n",
    "\n",
    "# Plot the eastward wind data using contourf\n",
    "cs = m.contourf(x, y, ds.eastward_wind[0, :, :], cmap='coolwarm', levels=levels)\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = m.colorbar(cs, location='right', pad=\"10%\",ticks=np.arange(-10, 11, 2))\n",
    "\n",
    "cbar.set_label(f'Eastward Wind ({ds.eastward_wind.units})')\n",
    "\n",
    "\n",
    "# Use Basemap to fill continents with white\n",
    "m.fillcontinents(color='white')\n",
    "\n",
    "# Draw coastlines (only coastlines, no rivers)\n",
    "m.drawcoastlines()\n",
    "\n",
    "# Add gridlines (parallels and meridians) for the Robinson projection\n",
    "m.drawparallels(np.arange(-90., 91., 30.), labels=[1, 0, 0, 0], linewidth=0.5, color='gray')\n",
    "m.drawmeridians(np.arange(-180., 181., 40.), labels=[0, 0, 0, 1], linewidth=0.5, color='gray')\n",
    "\n",
    "# Get the time of the data (assuming the first time step is relevant) for the title\n",
    "time = str(ds.coords['time'].values[0])\n",
    "# Set a dynamic title based on the dataset\n",
    "plt.title(f\"Eastward Wind at {time[:10]} ({ds.eastward_wind.units})\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece35893",
   "metadata": {},
   "source": [
    "Basemap converts the geographic coordinates (latitude and longitude) into a different coordinate system so we can correctly plot the data using the Robinson projection. The xarray.plot() function is designed for 2D Cartesian grids and does not inherently apply geographic projections like Robinson or Mercator.\n",
    "\n",
    "**Exercise 2: Copy the code from above and**:\n",
    "\n",
    "    1. Plot the northward_wind component.\n",
    "    2. Change the color of the landmasses.\n",
    "    3. Modify the color, linewidth, and spacing of the parallels and meridians.\n",
    "    4. Think about what else should be modified when plotting a new variable (e.g., color scale, units, or labels).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7de4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the code from above and modify\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e5741",
   "metadata": {},
   "source": [
    "# Data Reduction Techniques - Exploring Coarsen and Slice \n",
    "\n",
    "Now that you've explored various plotting techniques, you have a basic understanding of how zonal (eastward) and meridional (northward) wind velocities look. Wind, as a vector, has both a northward and eastward component, which are typically combined and represented as wind vectors. You might recognize this from weather apps, where wind direction and strength are often shown using arrows.\n",
    "\n",
    "We have plotted the wind components separately, but typically, wind data is represented using vector arrows to visually display both speed and direction. To do this, we can use the quiver() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2690d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Create a basemap instance (PlateCarree projection, which matches our lat/lon grid)\n",
    "m = Basemap(projection='cyl', llcrnrlat=-90, urcrnrlat=90, llcrnrlon=-180, urcrnrlon=180, resolution='c', ax=ax)\n",
    "\n",
    "# Draw coastlines and fill continents\n",
    "m.drawcoastlines()\n",
    "m.fillcontinents(color='white')\n",
    "\n",
    "# Draw map boundaries and lat/lon gridlines\n",
    "m.drawmapboundary()\n",
    "m.drawparallels(np.arange(-90., 91., 30.), labels=[1,0,0,0], linewidth=0.5)\n",
    "m.drawmeridians(np.arange(-180., 181., 60.), labels=[0,0,0,1], linewidth=0.5)\n",
    "\n",
    "\n",
    "\n",
    "# Convert the longitude and latitude from the xarray dataset for the quiver plot\n",
    "lon = ds.coords['lon'].values\n",
    "lat = ds.coords['lat'].values\n",
    "lon2d, lat2d = np.meshgrid(lon, lat)  # Create a meshgrid for quiver plotting\n",
    "\n",
    "# Quiver plot with wind vectors (zonal and meridional wind components)\n",
    "quiver_plot = ax.quiver(lon2d, lat2d, ds.eastward_wind, ds.northward_wind, scale=500)\n",
    "\n",
    "# Set labels and title\n",
    "plt.title('Wind Vector Plot (Eastward and Northward Components)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6d1f84",
   "metadata": {},
   "source": [
    "We encountered a `ValueError`, and no data were plotted. This likely happened because the `quiver()` function didnâ€™t expect the shape or size of the input data. With a horizontal resolution of 0.25Â°, the dataset generates a large number of arrows (720*1440 = 1036800), which can make the plot too dense and difficult to render.\n",
    "\n",
    "One solution to this issue is to downsample or slice the data to reduce the number of arrows being plotted.\n",
    "\n",
    "Whatâ€™s the difference between downsampling and slicing?\n",
    "\n",
    "    Downsampling involves reducing the resolution of the dataset by averaging or aggregating data onto a coarser grid. Instead of simply selecting fewer points, it creates a new, lower-resolution dataset by merging data from finer grids. This results in a smoother representation with fewer data points, while still capturing the overall pattern of the dataset.\n",
    "\n",
    "    Slicing involves selecting specific parts of the data based on intervals. For example, you might select every 20th point in the dataset to reduce the number of arrows plotted, making it more manageable.\n",
    "\n",
    "Let's start by testing slicing using `pu, pv = ds.eastward_wind[0, ::20, ::20], ds.northward_wind[0, ::20, ::20]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a48a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Create a basemap instance (PlateCarree projection, which matches our lat/lon grid)\n",
    "m = Basemap(projection='cyl', llcrnrlat=-90, urcrnrlat=90, llcrnrlon=-180, urcrnrlon=180, resolution='c', ax=ax)\n",
    "# Draw coastlines and fill continents\n",
    "m.drawcoastlines()\n",
    "m.fillcontinents(color='white')\n",
    "\n",
    "# Draw map boundaries and lat/lon gridlines\n",
    "m.drawmapboundary()\n",
    "m.drawparallels(np.arange(-90., 91., 30.), labels=[1,0,0,0], linewidth=0.5)\n",
    "m.drawmeridians(np.arange(-180., 181., 60.), labels=[0,0,0,1], linewidth=0.5)\n",
    "\n",
    "# Get the longitude and latitude data from the dataset\n",
    "pu, pv = ds.eastward_wind[0, ::20, ::20], ds.northward_wind[0, ::20, ::20]  # Slicing the wind data for clarity\n",
    "\n",
    "# Convert the longitude and latitude from the xarray dataset for the quiver plot\n",
    "lon = ds.coords['lon'].values[::20]\n",
    "lat = ds.coords['lat'].values[::20]\n",
    "lon2d, lat2d = np.meshgrid(lon, lat)  # Create a meshgrid for quiver plotting\n",
    "\n",
    "# Quiver plot with wind vectors (zonal and meridional wind components)\n",
    "quiver_plot = ax.quiver(lon2d, lat2d, pu, pv, scale=500)\n",
    "\n",
    "# Set labels and title\n",
    "plt.title('Wind Vector Plot (Eastward and Northward Components)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae8378f",
   "metadata": {},
   "source": [
    "The direction of the arrow represents the wind direction, while the length of the arrow indicates the wind speed.\n",
    "\n",
    "\n",
    "**Exercise 3: Copy the code from above and experiment with slicing. Try selecting every 10th or 50th point, and vary the slicing for the zonal latitude and longitude direction. What else do you need to consider? (For example, when slicing differently for each direction, remember to adjust latitude and longitude accordingly.)**\n",
    "\n",
    "You can also use `ds.eastward_wind[0, slice(None, None, Step), slice(None, None, Step)]`, where Step can be set to 20, 50, 10, or any other value depending on how much you want to slice the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59434e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the code from above and modify\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98cd740",
   "metadata": {},
   "source": [
    "Great! To create a more intelligible visualization, you employed data slicing. It's important to remember that slicing can omit certain values, possibly leading to a loss of information. An alternative is to use spatial averaging, which can be seamlessly achieved using the `coarsen method`. \n",
    "\n",
    "\n",
    "First, we need to calculate the wind speed: \n",
    "To find the wind speed, `U`, from the eastward (u) and northward (v) components, use:\n",
    "\n",
    "$$U = \\sqrt{u^2 + v^2}$$  \n",
    "\n",
    "\n",
    "**Exercise 4: Use  `np.sqrt()`in numpy to compute `U`. Plug in your data for u and v. Ensure the units and name attributes in your xarray data array are correct. Update the metadata attributes of your xarray data array (`wind_speed.attrs['units'] = 'UNIT' , wind_speed.attrs['long_name'] = 'NAME OF VARIABLE'`). Then, plot U with your preferred method.**\n",
    "\n",
    "\n",
    "Tip: To square a value in Python, use `**`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5aeb9f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your computation and plot of wind speed here\n",
    "wind_speed = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9102430",
   "metadata": {},
   "source": [
    "#### Common Statistical Operations in Python\n",
    "\n",
    "In Python, especially with libraries like xarray, numpy, or pandas, you can perform various statistical operations by appending methods like .mean(), .std(), or .sum() to your data structures. Downsampling, or reducing data resolution using methods like [`coarsen()`](https://docs.xarray.dev/en/stable/generated/xarray.DataArray.coarsen.html), can be useful for several reasons, such as improving performance, aligning data with coarser grids, or reducing noise for analysis. For example, when reducing resolution from 0.25Â° to 1Â°, you can use a window size of 4 and apply functions like .mean(). Donâ€™t forget to update metadata, such as units, after downsampling.     \n",
    "\n",
    "\n",
    "**Exercise 5**:  \n",
    "1. Average the data onto a 1Â°x1Â° grid. Name it `coarsened_mean`\n",
    "2. Update attributes\n",
    "3. Plot the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d87ada96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your calculation here\n",
    "coarsened_mean = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19522df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your plot here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8421a0c6",
   "metadata": {},
   "source": [
    "In the following, we plot the wind vectors together with the absolute wind speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c756bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "\n",
    "# run this cell\n",
    "\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Create a basemap instance (PlateCarree projection, which matches our lat/lon grid)\n",
    "m = Basemap(projection='cyl', llcrnrlat=-90, urcrnrlat=90, llcrnrlon=-180, urcrnrlon=180, resolution='c', ax=ax)\n",
    "# Draw coastlines and fill continents\n",
    "\n",
    "#m.fillcontinents(color='white')\n",
    "m.drawcoastlines()\n",
    "# Draw map boundaries and lat/lon gridlines\n",
    "m.drawmapboundary()\n",
    "m.drawparallels(np.arange(-90., 91., 30.), labels=[1,0,0,0], linewidth=0.5)\n",
    "m.drawmeridians(np.arange(-180., 181., 60.), labels=[0,0,0,1], linewidth=0.5)\n",
    "\n",
    "# Get the longitude and latitude data from the dataset\n",
    "pu, pv = ds.eastward_wind[0, ::20, ::20], ds.northward_wind[0, ::20, ::20]  # Slicing the wind data for clarity\n",
    "\n",
    "# Convert the longitude and latitude from the xarray dataset for the quiver plot\n",
    "lon = ds.coords['lon'].values[::20]\n",
    "lat = ds.coords['lat'].values[::20]\n",
    "lon2d, lat2d = np.meshgrid(lon, lat)  # Create a meshgrid for quiver plotting\n",
    "# Create a meshgrid for plotting\n",
    "lon2dc, lat2dc = np.meshgrid(coarsened_mean.lon, coarsened_mean.lat)\n",
    "\n",
    "# Transform the coordinates into the Robinson projection\n",
    "x, y = m(lon2dc, lat2dc)\n",
    "levels = np.linspace(0, 12, 30)\n",
    "cs = m.contourf(x, y, coarsened_mean, cmap='viridis', levels=levels)\n",
    "# Add a color bar for the contourf plot\n",
    "cbar = m.colorbar(cs, location='right', pad=\"10%\",ticks=np.arange(0, 14, 2))\n",
    "cbar.set_label(f'Coarsened Wind Speed ({coarsened_mean.units})')\n",
    "# After contourf, fill continents with white\n",
    "m.fillcontinents(color='white')\n",
    "# Quiver plot with wind vectors (zonal and meridional wind components)\n",
    "quiver_plot = ax.quiver(lon2d, lat2d, pu, pv, scale=500)\n",
    "\n",
    "# Set labels and title\n",
    "plt.title('Wind Vector Plot (Eastward and Northward Components)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee287219",
   "metadata": {},
   "source": [
    "We use the gridded wind vectors and coarsened wind speed for this plot. Ideally, the wind vectors should also be coarsened instead of simply sliced to ensure better comparability with the coarsened wind speed. Despite this, the plot clearly shows regions with higher wind speeds and more prominent wind vectors, while in the blue-shaded areas with lower speeds, the arrows are also smaller.\n",
    "\n",
    "**Extra Exercise: Coarsen the zonal and meridional wind vectors and plot them together with the coarsened wind speed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7525ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Excercise "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f14a34",
   "metadata": {},
   "source": [
    "Plotting is more efficient on a coarser grid. However, is it always appropriate? Compute the standard deviation within each grid cell and assess the variability that might be obscured due to the coarser gridding.  \n",
    "\n",
    "**Exercise 6:**  \n",
    "1. Compute standard deviation (std) of `wind_speed` within each 1Â°x1Â° grid cell and name it `coarsened_std`\n",
    "2. Update attributes\n",
    "3. Visualize the std as a contourplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f9d5ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your calculation here \n",
    "coarsened_std = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c33904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your plot here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79651aee",
   "metadata": {},
   "source": [
    "**Note:** The plot shows pronounced spatial variability in certain areas. The right grid resolution is crucial and varies based on whether you're studying broad or fine details, relevant in both atmospheric and ocean data. \n",
    "\n",
    "To summarize, both `slicing` and `coarsen` offer distinct methodologies for handling and visualizing large datasets. While slicing is a direct approach to selectively display data, making visualizations more intelligible, coarsen provides a more comprehensive representation by spatially averaging the data. This ensures key information is retained, but the spatial variability within the data is smoothed out. This is because it averages over specified spatial windows, and as a result, finer-scale variations that fall below the size of this window are effectively lost or averaged out.  \n",
    "\n",
    "For big patterns, a coarser grid works. For detailed studies on small phenomena, use a fine grid and perhaps zoom into an area of interest.  To achieve this, we can slice the data. Unlike before, where you might pick any x-value for latitude or longitude, we can now select a specific box using `wind_speed_sliced = wind_speed.sel(lon=slice(lon min, lon_max),lat=slice(lat_min, lat_max))`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901f26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the cell\n",
    "\n",
    "# Define the Indian Ocean region: \n",
    "# Approximate bounds: Longitude 20Â°E to 120Â°E, Latitude -60Â°S to 30Â°N\n",
    "lon_min, lon_max = 20, 120\n",
    "lat_min, lat_max = -60, 30\n",
    "\n",
    "# Slice the wind speed data for the Indian Ocean region\n",
    "wind_speed_sliced = wind_speed.sel(lon=slice(lon_min, lon_max), lat=slice(lat_min, lat_max))\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Define the map projection, but zoom in on the Indian Ocean\n",
    "m = Basemap(projection='cyl', \n",
    "            llcrnrlon=lon_min, urcrnrlon=lon_max,  # Set longitude bounds\n",
    "            llcrnrlat=lat_min, urcrnrlat=lat_max,  # Set latitude bounds\n",
    "            ax=ax)\n",
    "\n",
    "# Get longitude and latitude data from the sliced dataset\n",
    "lon2d, lat2d = np.meshgrid(wind_speed_sliced.lon, wind_speed_sliced.lat)\n",
    "\n",
    "\n",
    "# Define levels for contouring the wind speed\n",
    "levels = np.linspace(0, np.max(wind_speed_sliced), 15)\n",
    "\n",
    "# Plot the wind speed data using contourf\n",
    "cs = m.contourf(lon2d, lat2d, wind_speed_sliced, cmap='viridis', levels=levels)\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = m.colorbar(cs, location='right', pad=\"10%\", ticks=np.arange(0, 14, 2))\n",
    "\n",
    "cbar.set_label(f'Wind Speed ({wind_speed_sliced.units})')\n",
    "\n",
    "# Use Basemap to fill continents with white\n",
    "m.fillcontinents(color='white')\n",
    "\n",
    "# Draw coastlines (only coastlines, no rivers)\n",
    "m.drawcoastlines()\n",
    "\n",
    "\n",
    "# Add gridlines (parallels and meridians) for the Indian Ocean region\n",
    "m.drawparallels(np.arange(lat_min, lat_max + 10, 10), labels=[1, 0, 0, 0], linewidth=0.5, color='gray')\n",
    "m.drawmeridians(np.arange(lon_min, lon_max + 20, 20), labels=[0, 0, 0, 1], linewidth=0.5, color='gray')\n",
    "\n",
    "# Get the time of the data (assuming the first time step is relevant) for the title\n",
    "time = str(ds.coords['time'].values[0])\n",
    "\n",
    "# Set a dynamic title based on the dataset\n",
    "plt.title(f\"Wind Speed over Indian Ocean at {time[:10]} ({wind_speed_sliced.units})\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d2e69c",
   "metadata": {},
   "source": [
    "**Extra Exercise: Slice a region in the Northern North Atlantic.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49919278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66a6c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec1831a",
   "metadata": {},
   "source": [
    "# Key Learnings:\n",
    "\n",
    "\n",
    "**Scientific Modules:** You've worked with numpy and xarray, both crucial in handling and analyzing scientific data in Python.\n",
    "\n",
    "**Variables and Types:** You've interacted with various data types like floats, arrays, and DataArrays in xarray, understanding how to manipulate and process them.\n",
    "\n",
    "**Operators and Comparisons:** You've used mathematical operations in slicing and transforming data and made comparisons when selecting regions (e.g., slicing wind speed data by latitude and longitude).\n",
    "\n",
    "**Linear Algebra:** You've dealt with vector data, like the zonal and meridional wind components, and their role in wind vector calculations.\n",
    "\n",
    "**Scientific Algorithms:** You've calculated means and standard deviations (e.g., resampling or coarsening data) to summarize wind speed data, a fundamental part of statistical analysis.\n",
    "\n",
    "**Exceptions and Error Handling:**You navigated errors like ValueError and projection issues when plotting, which required adjusting your approach to ensure the code executed properly.\n",
    "\n",
    "**Visualization, Plotting, and Data Organization:** Youâ€™ve extensively worked on visualization tasks using matplotlib and Basemap to represent data with wind vector plots and contour maps. You've also made adjustments to plot wind speed and zonal/meridional wind components.\n",
    "\n",
    "**Data Extraction and Manipulation:**You've sliced and extracted specific regions of datasets, e.g., focusing on the Indian Ocean for wind speed visualization. Youâ€™ve also resampled data spatially using xarray operations.\n",
    "\n",
    "**Spatial Data Resampling:** Youâ€™ve applied resampling techniques (coarsening) to reduce the resolution of data for more manageable computations and better visualization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
