{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:red;\">If you are using Binder instead of downloading the repository and working locally, this script might not run due to the relatively large datasets and Binder's limited resources. I recommend working locally on your own computer for optimal performance.</p>**\n",
    "\n",
    "\n",
    "\n",
    "# Transitioning from Surface Data to Vertical Profiles\n",
    "\n",
    "In previous sessions, we focused on surface data, particularly wind and sea surface temperature (SST). Now, we transition to analyzing vertical profiles using Argo data, which provide temperature and  salinity and their uncertainty at various depths. Unlike the SST data from Session 2, which was accessed via OPeNDAP, here we work with objectively mapped Argo data, downloaded over HTTPS. We will download, process, and combine these datasets, incorporating error handling and logical conditions such as if-else statements to ensure robustness.\n",
    "\n",
    "**<p style=\"color:royalblue;\">A brief exploration of gridding techniques for in situ data can be found in the notebook `IntroGridding.ipynb`.</p>**\n",
    "\n",
    "In this session, we will explore both horizontal and vertical patterns of temperature, salinity, and depth across different ocean basins. You will calculate and analyze mixed layer depth, and determine the annual amplitude of the seasonal cycle for various variables. Additionally, you will calculate parameters averaged over the mixed layer and assess whether surface measurements can serve as reliable proxies for mixed layer processes.\n",
    "\n",
    "Run the next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import os\n",
    "import requests \n",
    "import zipfile\n",
    "import xarray as xr \n",
    "import numpy as np \n",
    "import gsw\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import holoviews as hv\n",
    "#from IPython.display import Image\n",
    "import hvplot.xarray\n",
    "hv.extension('bokeh')\n",
    "#plt.rcParams['figure.figsize'] = (12,7)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the necessary libraries, we load the Argo data from EN4 using the HTTPS protocol. These datasets are available via the Met Office website at: https://www.metoffice.gov.uk/hadobs/en4/download-en4-2-2.html. We select the objectively analyzed data, which have been error-corrected and include uncertainty information. In the following code, we use a .txt file that contains the list of datasets we want to download. The code requests the datasets and uses if-else statements to manage the download process, ensuring that files are downloaded - if necessary, unzipped - , and processed. Additionally, the code now checks if the zip files already exist, in which case they are simply read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cell\n",
    "\n",
    "# Define the folder where files will be saved and unzipped\n",
    "save_directory = '../Data/EN4'\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Read the list of URLs from the download list file\n",
    "with open('../Data/EN4/EN.4.2.2.analyses.g10.download-list.txt') as f:\n",
    "    urls = f.readlines()\n",
    "\n",
    "# List to store the paths of extracted NetCDF files\n",
    "nc_files = []\n",
    "\n",
    "# Loop through each URL, download, unzip, and collect NetCDF file paths\n",
    "for url in urls:\n",
    "    url = url.strip()  # Clean up the URL\n",
    "    if url:  # Check if the URL is not empty\n",
    "        file_name = url.split('/')[-1].strip()\n",
    "        file_path = os.path.join(save_directory, file_name)\n",
    "        \n",
    "        # Check if the zip file already exists\n",
    "        if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
    "            print(f\"{file_name} already exists. Skipping download.\")\n",
    "        else:\n",
    "            # Download the file\n",
    "            print(f\"Downloading {file_name} to {file_path}...\")\n",
    "            r = requests.get(url)\n",
    "        \n",
    "            if r.status_code == 200: # sucessful request\n",
    "                # Save the zip file\n",
    "                with open(file_path, 'wb') as file:\n",
    "                    file.write(r.content)\n",
    "                \n",
    "                # Check if the file exists and is not empty\n",
    "                if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
    "                    print(f\"{file_name} downloaded successfully.\")\n",
    "                else:\n",
    "                    print(f\"Failed to download {file_name}, file not found or empty.\")\n",
    "                    continue\n",
    "            else:\n",
    "                print(f\"Failed to download {file_name}, status code: {r.status_code}\")\n",
    "                continue\n",
    "        \n",
    "        # Unzip the file and collect NetCDF file paths\n",
    "        print(f\"Extracting {file_name}...\")\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(save_directory)\n",
    "            for extracted_file in zip_ref.namelist():\n",
    "                if extracted_file.endswith('.nc'):\n",
    "                    print(f\"Found {extracted_file}\")\n",
    "                    nc_files.append(os.path.join(save_directory, extracted_file))\n",
    "\n",
    "# Use open_mfdataset to combine all NetCDF files into a single dataset\n",
    "if nc_files:\n",
    "    ds_en4 = xr.open_mfdataset(nc_files, combine='by_coords')\n",
    "    print(ds_en4)\n",
    "else:\n",
    "    print(\"No datasets downloaded or processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Exercise**:\n",
    "\n",
    "Explore the dataset you just loaded by answering the following questions:\n",
    "\n",
    "    What is the shape of the dataset?\n",
    "    Examine the dimensions and size of the dataset.\n",
    "\n",
    "    Which variables are contained within the dataset?\n",
    "    List the variables provided in the dataset and their descriptions.\n",
    "\n",
    "    What is the resolution of the data?\n",
    "    Analyze the spatial resolution of the dataset.\n",
    "\n",
    "    What units are the data presented in?\n",
    "    Investigate the units of measurement for the variables in the dataset.\n",
    "\n",
    "    \n",
    "\n",
    "Use the appropriate methods like e.g. .dims, .data_vars, and .attrs to extract this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to get the dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to get the variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code to get the horizontal resolution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code to get the units of each variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What is the vertical spacing between depth levels?\n",
    "\n",
    "Examine the differences between consecutive depth levels to understand the vertical structure of the dataset.\n",
    "\n",
    "Tip: You can use `np.diff()` to calculate the differences between consecutive depth levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we plot the temperature.\n",
    "\n",
    "### Plotting with hvplot:\n",
    "\n",
    "We use hvplot because it allows us to explore multidimensional datasets interactively and efficiently. This is particularly useful for visualizing datasets with 3 or 4 dimensions (e.g., time, longitude, latitude, and depth). `hvplot` integrates seamlessly with xarray, enabling us to create dynamic, interactive plots that help us better understand complex oceanographic data.\n",
    "\n",
    "For instance, when we visualize temperature using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cell\n",
    "\n",
    "ds_en4.temperature.hvplot('lon', 'lat', width=700, height=400)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to plot temperature across different longitudes and latitudes, with interactive sliders that let us explore additional dimensions, such as time and depth. By leveraging hvplot, we gain an intuitive understanding of the dataset's spatial and temporal variability.\n",
    "\n",
    "\n",
    "\n",
    "**2. Exercise**: \n",
    "\n",
    "Convert the temperature from Kelvin to Celsius and then visualize it using `hvplot`.   \n",
    "After converting the temperature, update the units in the dataset to reflect the change from Kelvin to Celsius. You can also customize the plot by setting color limits (`clim`) and choosing a different colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code and plot here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Depth Levels in EN4\n",
    "\n",
    "Unlike the datasets we have explored previously, the EN4 dataset includes data at various depth levels. This allows us to examine how variables such as temperature and salinity change not just horizontally but also vertically throughout the ocean.\n",
    "\n",
    "We create a vertical section plot. Specifically, we will plot a temperature section in the Pacific Ocean at 220°E (which is equivalent to 140°W)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cell\n",
    "pacific_section = ds_en4.sel(lon = 220) # 220-360= -140 -> Pacific\n",
    "pacific_section['depth'] = -1 * pacific_section['depth']  # Invert depth\n",
    "pacific_section.temperature[:,:35,:].hvplot.quadmesh('lat', 'depth', clim=(0, 30), cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the Atlantic at 30°W:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cell\n",
    "\n",
    "atlantic_section = ds_en4.sel(lon = 330) #30°W\n",
    "atlantic_section['depth'] = -1 * atlantic_section['depth']  # Invert depth\n",
    "atlantic_section.temperature[:,:35,:].hvplot.quadmesh('lat', 'depth', clim=(0, 30), cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will modify the plot by using contour lines for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATLANTIC\n",
    "# run the cell\n",
    "#with contours\n",
    "atlantic_section = ds_en4.sel(lon=330)  # 30°W\n",
    "atlantic_section['depth'] = -1 * atlantic_section['depth']  # Invert depth\n",
    "\n",
    "# Plot filled temperature contours\n",
    "atlantic_section.temperature[:,:35,:].hvplot.contourf(\n",
    "    x='lat', \n",
    "    y='depth', \n",
    "    levels=30,  # Number of contour levels\n",
    "    cmap='RdBu_r',  # Reversed red-blue colormap\n",
    "    clim=(-2, 30), \n",
    "    width=700, \n",
    "    height=400, \n",
    "    title='Atlantic Temperature Filled Contours at 30°W'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PACIFIC\n",
    "# run the cell\n",
    "# with contours \n",
    "# Plot filled temperature contours\n",
    "pacific_section.temperature[:,:35,:].hvplot.contourf(\n",
    "    x='lat', \n",
    "    y='depth', \n",
    "    levels=10,  # Number of contour levels\n",
    "    cmap='RdBu_r',  # Reversed red-blue colormap\n",
    "    clim=(-2, 30), \n",
    "    width=700, \n",
    "    height=400, \n",
    "    title='Pacific Temperature Filled Contours at 140°W'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Observations\n",
    "\n",
    "....\n",
    "\n",
    "\n",
    "**3. Exercise**:\n",
    "\n",
    "Now that you've converted and visualized the temperature data in Celsius, it's time to explore further by observing the salinity and uncertainties in both temperature and salinity. As you work through this exercise, take note of key patterns and observations.\n",
    "\n",
    "**Observe Salinity**:\n",
    "\n",
    "- Plot the salinity data across longitude and latitude in a similar way to the temperature plot.  \n",
    "- Plot the salinity data across depth and longitude using the `atlantic_section` and `pacific_section`. Instead of temperature, you will be plotting salinity in this case.  \n",
    "- Plot the uncerteinty of both, temperature and salinity\n",
    "- Task: Compare the temperature and salinity distributions. What patterns do you notice? How do salinity vary spatially? Consider differences between ocean regions, latitudinal gradients, and any other patterns that catch your attention.\n",
    "\n",
    "**Example code to visualize salinity**:\n",
    "\n",
    "  \n",
    "`ds_en4.salinity.hvplot('lon', 'lat', clim=(30, 40), cmap='viridis', width=700, height=400, title='Salinity')`\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to plot the Pacific Section \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to plot the Atlantic Section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the uncertainty of salinity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the uncerteinty of temperature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Salinity and Uncertainty Observations here**\n",
    "\n",
    "....\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Connecting Back to Session 2 and Introducing the Vertical Section\n",
    "\n",
    "In Session 2, we analyzed sea surface temperature (SST) data over an extended period and calculated both anomalies and ENSO composites. If you're not familiar with this, I recommend revisiting Session 2 and reviewing the exercises.\n",
    "\n",
    "We observed that temperature anomalies during ENSO events exhibit significant amplitude in the central Pacific, particularly around the equator. \n",
    "\n",
    "\n",
    "To better understand this, let’s first take a look at the next diagram, which shows the variation of surface temperatures over time and longitude along the equator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enso_section = ds_en4.sel(lat =0,lon = slice(200,260)) #160°W-100°W\n",
    "enso_section['depth'] = -1 * enso_section['depth']  # Invert depth\n",
    "\n",
    "\n",
    "# Select the first depth level for the Hovmöller plot\n",
    "first_depth_level = enso_section.isel(depth=0)  # First available depth level\n",
    "\n",
    "# Create a Hovmöller plot: time vs longitude at the equator for the first depth level\n",
    "hovmoeller_plot = first_depth_level.temperature.hvplot.quadmesh('time', 'lon', \n",
    "                                                                           clim=(25, 30), cmap='coolwarm', width=700, height=400, invert = True)\n",
    "\n",
    "# Display the plot\n",
    "hovmoeller_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is called a Hovmöller diagram an it is very often used in oceanography/climatology.  \n",
    "\n",
    "**Question**: How would you describe its characteristics?\n",
    "\n",
    "- What patterns do you observe over time?\n",
    "- Can you identify significant events, such as El Niño or La Niña? What are their characteristics?\n",
    "\n",
    "\n",
    "\n",
    "In the Hovmöller diagram, which shows absolute temperatures at the surface along the equator, we can already observe significant differences in temperature across time and longitude. These differences are closely linked to the El Niño-Southern Oscillation (ENSO) cycle.\n",
    "\n",
    "Temperature Gradients: Notice how the western Pacific generally has much warmer surface temperatures than the eastern Pacific. This persistent gradient reflects the typical climate state of the tropical Pacific, where warm water piles up in the west due to the trade winds.\n",
    "\n",
    "ENSO Influence: During El Niño events, the warm water that is usually confined to the western Pacific shifts eastward, resulting in warmer-than-usual temperatures across the central and eastern Pacific. Conversely, during La Niña events, cold upwelling in the eastern Pacific intensifies, leading to a stronger east-west temperature gradient with colder temperatures in the east and warmer temperatures in the west.\n",
    "\n",
    "\n",
    "\n",
    "But what happens below the surface? How do these patterns extend vertically through the water column?\n",
    "\n",
    "In the following section, we will take a closer look at the vertical temperature structure along the central Pacific, from 160°W to 100°W, to explore how ENSO impacts not just the surface but the entire vertical profile of the ocean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cell\n",
    "\n",
    "enso_section.temperature[:,:20,:].hvplot.contourf(\n",
    "    x='lon', \n",
    "    y='depth', \n",
    "    levels=10,  # Number of contour levels\n",
    "    cmap='coolwarm',  # Reversed red-blue colormap\n",
    "    clim=(10, 30), \n",
    "    width=700, \n",
    "    height=400, \n",
    "    title='Pacific Temperature Filled Contours at the equator'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining the Temperature Section and ENSO Influence\n",
    "\n",
    "When plotting this temperature section along the equator, we can observe differences between the temperatre especially between 2022 and 2023. This region is strongly influenced by ENSO (El Niño-Southern Oscillation) events. During this period, several La Niña events were followed by an El Niño at the end of 2023, and this is reflected in the temperature patterns.\n",
    "\n",
    "One notable feature is that surface temperatures are generally higher in the western Pacific, while the thermocline (the boundary between warm surface water and colder deep water) is tilted. In the west, the warm water extends much deeper than in the east.\n",
    "\n",
    "This tilting of the thermocline is a classic feature of ENSO. During La Niña events, the easterly trade winds strengthen, pushing warm water toward the western Pacific and deepening the thermocline there, while in the eastern Pacific, upwelling brings colder water to the surface. Conversely, during El Niño events, these trade winds weaken or reverse, causing the warm water to shift eastward and leads to higher surface temperatures in the central and eastern Pacific.\n",
    "\n",
    "In summary, the tilting thermocline and the warm water depth differences are strongly related to the ENSO cycle, reflecting the dynamic interplay between ocean temperatures and atmospheric wind patterns in this region.\n",
    "\n",
    "The following picture from US National Weather Service briefly describes the La Nina phenomenon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the cell\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "# How to display an image from a URL\n",
    "Image(url='https://blog.csiro.au/wp-content/uploads/2014/06/la-nic3b1a.jpg', width=500, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density\n",
    "\n",
    "The differences in temperature across the Pacific are not just restricted to the surface—they also impact the vertical structure of the ocean. These temperature variations have a direct influence on density, which is a function of both temperature and salinity. Warmer water is less dense than colder water, which leads to stratification of the water column.\n",
    "\n",
    "This stratification determines the Mixed Layer Depth (MLD). ENSO events can cause the MLD to shift, as the position of the pycnocline (which is where the water density changes rapidly with depth) changes in response to e.g. warming or cooling of the surface waters.\n",
    "\n",
    "\n",
    "Next, we’ll explore how these temperature differences impact the density and MLD in the Pacific.\n",
    "\n",
    "We will use the GSW (Gibbs SeaWater) library to calculate pressure, potential temperature, and potential density from the available temperature, depth, and salinity data. Further information: https://www.teos-10.org/pubs/gsw/html/gsw_contents.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cell \n",
    "\n",
    "# Calculate pressure based on depth\n",
    "depth = ds_en4['depth']\n",
    "lat = ds_en4['lat']\n",
    "pressure = gsw.p_from_z(-depth, lat)\n",
    "\n",
    "# Calculate potential temperature and density\n",
    "temp = ds_en4['temperature']\n",
    "sal = ds_en4['salinity']\n",
    "ptemp = gsw.pt0_from_t(sal, temp, pressure)\n",
    "sigma0 = gsw.sigma0(sal, ptemp)\n",
    "\n",
    "# Set correct attributes for the potential density variable\n",
    "sigma0.name = 'Potential Density'\n",
    "sigma0.attrs['long_name'] = 'Potential Density (Sigma_0)'\n",
    "sigma0.attrs['units'] = 'kg m-3'\n",
    "\n",
    "# Remove unwanted attributes that are inherited from the original salinity data\n",
    "sigma0.attrs.pop('valid_min', None)\n",
    "sigma0.attrs.pop('valid_max', None)\n",
    "sigma0.attrs.pop('standard_name', None)\n",
    "\n",
    "# Set correct attributes for the potential density variable\n",
    "ptemp.name = 'Potential Temperature'\n",
    "ptemp.attrs['long_name'] = 'Potential Temperature'\n",
    "ptemp.attrs['units'] = '°C'\n",
    "\n",
    "# Remove unwanted attributes that are inherited from the original salinity data\n",
    "ptemp.attrs.pop('valid_min', None)\n",
    "ptemp.attrs.pop('valid_max', None)\n",
    "ptemp.attrs.pop('standard_name', None)\n",
    "\n",
    "\n",
    "\n",
    "ds_en4['ptemp'] = ptemp\n",
    "ds_en4['sigma0'] = sigma0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the density section at the same location as the previous temperature section at the equator. When viewing the density section, corresponding patterns to temperature become apparent, indicating that especially temperature changes have an impact on density variations in the ENSO regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cell to see the plot\n",
    "sigma_enso = sigma0.sel(lat =0,lon = slice(200,260)) #160°W-100°W\n",
    "sigma_enso['depth'] = -1 * sigma_enso['depth']  # Invert depth\n",
    "\n",
    "sigma_enso[:,:20,:].hvplot.contourf(\n",
    "    x='lon', \n",
    "    y='depth', \n",
    "    levels=20,  # Number of contour levels\n",
    "    cmap='coolwarm',  # Reversed red-blue colormap\n",
    "    clim=(21, 27), \n",
    "    width=700, \n",
    "    height=400, \n",
    "    title='Pacific Density Filled Contours at the equator'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the MLD, we use a density threshold, which calculates the MLD based on a change in potential density (0.03 kg m-3) starting from 5 meters depth (the first depth layer). The mixed layer facilitates energy transfer from the air to the water and is also a zone where biological activity is generally enhanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cell\n",
    "\n",
    "# select density of the uppermost layer\n",
    "surface_density = sigma0.isel(depth=0)\n",
    "\n",
    "# Calculate the density difference between the surface and each depth level\n",
    "density_diff = sigma0 - surface_density\n",
    "\n",
    "# Define a density threshold for MLD calculation (0.03 kg/m³)\n",
    "density_threshold = 0.03\n",
    "\n",
    "\n",
    "mask = density_diff >= density_threshold\n",
    "\n",
    "# Apply the function to calculate MLD based on the surface difference\n",
    "mld_from_surface_difference = depth.where(mask).min(dim='depth')\n",
    "\n",
    "# Add Mixed Layer Depth to the dataset\n",
    "ds_en4['mld'] = mld_from_surface_difference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Exercise: Plot the mean MLD over time. What do you observe?**\n",
    "\n",
    "Use `hvplot()`  for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual Amplitude \n",
    "\n",
    "**5. Exercise**:  \n",
    "In this exercise, you will explore how to calculate the amplitude of the seasonal cycle and determine the variability on an interannual scale from mixed layer depth (MLD) data. We want to investigate where the MLD shows a strong seasonal cycle and where interannual variability dominates.\n",
    "\n",
    "Tip: We've previously calculated the climatological seasonal cycle (in Session 2). How can this be utilized to compute the annual amplitude?\n",
    "\n",
    "**<p style=\"color:royalblue;\">Given that we only have four years of data, the results may not be fully representative, but they can still provide useful insights. Think about how you would approach the calculation of the seasonal amplitude and how you would assess the interannual variability. Consider removing the seasonal cycle to isolate interannual fluctuations.</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to calculate the annual amplitude of MLD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now: Removing Seasonal Variations to Analyze Remaining Variability**\n",
    "\n",
    "Now, remove the seasonal variations from the MLD data in order to focus on the remaining interannual variability. Even though we are working with only four years of data and not applying a detrending approach, this method helps isolate fluctuations beyond the regular seasonal cycle, providing insights into longer-term variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to calculate the interannual variability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: What do you observe?**  \n",
    "Where does the seasonal cycle dominate, and where are interannual changes more pronounced?\n",
    "\n",
    ".... \n",
    "Your Observations:\n",
    "\n",
    "- The seasonal cycle is dominant in mid- and high-latitude regions, where processes such as cooling, melting of sea ice, and ocean currents have an influence on density.\n",
    "- In equatorial regions, the seasonal and interannual variability is lower, with less pronounced changes in MLD.\n",
    "- Interannual variability in MLD is most noticeable around ~50°S and north of ~50°N.\n",
    "\n",
    "These patterns could be linked to large-scale atmospheric and oceanic processes, such as the influence of westerly winds, shifting ocean currents, and changes in sea ice extent.\n",
    "\n",
    "**<p style=\"color:royalblue;\">Keep in mind that we are analyzing only four years of data; longer time series would be better suited for analyzing interannual variability in detail.</p>**\n",
    "\n",
    "\n",
    "**6. Exercise**: \n",
    "1. Calculate the annual amplitude of your dataset `ds_en4` from the first depth layer and plot salinity. \n",
    "2. Average the salinity and temperature within the mixed layer. Then, calculate and plot the annual amplitude of the mixed layer salinity and temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to calculate the annual amplitude of ds_en4 and plot salinity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional: Plot the annual amplitude of temperature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average the `ds_en4` variables within the MLD, then calculate the annual amplitude and plot salinity.\n",
    "\n",
    "Tip: Use a mask to select only the data within the Mixed Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Exercise**:  \n",
    "Consider how you can confirm that only the data within the mixed layer depth (MLD) are included in the calculation. To verify this, you could plot the masked salinity data to visually check whether the masking based on the MLD was applied correctly. This can be useful for debugging and ensuring that only the intended data are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Exercise** (for this session):\n",
    "\n",
    "Calculate and Plot the RMSE:\n",
    "\n",
    "- Calculate the RMSE between salinity in the first layer and the mixed layer salinity.\n",
    "- Repeat the same for temperature.\n",
    "- Plot both RMSE values on separate plots.\n",
    "\n",
    "The Root Mean Square Error (RMSE) is calculated using the following formula:\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (x_i - y_i)^2}\n",
    "$$\n",
    "​\n",
    "\n",
    "Where:\n",
    "\n",
    "$x_i$​ are the values from the first layer (e.g. salinity or temperature).  \n",
    "$y_i​$ are the values from the mixed layer.  \n",
    "$N$ is the number of data points.\n",
    "\n",
    "**<p style=\"color:royalblue;\">RMSE is typically used to measure the differences between predicted and observed (or true) values. In this case, we are using it to compare surface values (first layer) with mixed layer values, helping us assess the variability between these two layers.</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# Calculate RMSE between variable at surface and variable averaged in the Mixed Layer\n",
    "\n",
    "# Step 1: Compute the difference between your variables in the first layer and mixed layer averaged variables at each time step\n",
    "difference = \n",
    "\n",
    "# Step 2: Square the differences\n",
    "squared_difference = \n",
    "\n",
    "# Step 3: Compute the mean of the squared differences over time\n",
    "mean_squared_difference = \n",
    "# Step 4: Take the square root to get the RMSE\n",
    "rmse = \n",
    "\n",
    "# Step 5: Plot the RMSE to visualize where salinity is a better or worse proxy for mixed layer salinity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot rmse of ptemp\n",
    "\n",
    "rmse['ptemp'].hvplot(clim=(0, .5), cmap='inferno', title='RMSE between Temperature and Mixed Layer Temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE provides a measure of the average difference between the values in the first layer and the mixed layer. A higher RMSE indicates greater variability or inconsistency between the two layers, suggesting that conditions in the first layer and the mixed layer differ significantly. Conversely, a lower RMSE indicates that the first layer and mixed layer have similar properties, meaning that, for example, salinity in the first layer is a good proxy for the mixed layer.\n",
    "\n",
    "This is particularly interesting because we often rely on satellite data due to their high spatial and temporal resolution, whereas in-situ data typically have more limited coverage. Satellites allow us to rapidly obtain global datasets, but the challenge is to determine whether surface measurements are sufficient to accurately represent the processes occurring in the mixed layer—the layer that is in direct contact and exchange with the atmosphere. Understanding this can help improve our ability to use surface satellite observations to infer subsurface processes in the ocean's mixed layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the cell to save the uppermost variables from ds_en4\n",
    "\n",
    "ds_en4[['salinity','sigma0','mld']].isel(depth=0).to_netcdf('../Data/EN4/EN4_uppermost_2020_2023.nc', engine='h5netcdf', compute=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the dataset and remove all .nc files from the EN4 folder to save space\n",
    "ds_en4.close()\n",
    "for file in nc_files:\n",
    "    os.remove(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
